# 通用数据同步框架 DataX
#docslug#/oceanbase-database/oceanbase-database/V4.0.0/general-purpose-data-synchronization-framework-2
DataX 是阿里巴巴集团内部广泛使用的离线数据同步工具/平台，它支持 MySQL、Oracle、HDFS、Hive、OceanBase、HBase、OTS、ODPS 等各种异构数据源之间高效的数据同步功能。

## DataX 简介

DataX 本身作为数据同步框架，将不同数据源的同步抽象为从源头数据源读取数据的 Reader 插件，以及向目标端写入数据的 Writer 插件，理论上 DataX 框架可以支持任意数据源类型的数据同步工作。同时 DataX 插件体系作为一套生态系统，每接入一套新数据源该新加入的数据源即可实现和现有的数据源互通。

基于 DataX 的同步机制，可以通过 OceanBase 数据库的 Reader 和 Writer 插件实现 OceanBase 数据库跨数据库、集群和异构数据库的数据迁移。

DataX 安装使用，请参考 [DataX-userGuid](https://github.com/alibaba/DataX/blob/master/userGuid.md)。DataX 已经在 github 开源，更多详细内容请参考 [Alibaba-datax](http://github.com/Alibaba/datax)。DataX 还有其商业版 Dataworks（大数据开发治理平台） ，提供了专业高效、安全可靠的一站式大数据开发与治理平台。

## DataX 框架设计

![开发者指南-迁移数据-DataX框架](https://help-static-aliyun-doc.aliyuncs.com/assets/img/zh-CN/4421957461/p419997.png)

DataX 作为离线数据同步框架，采用 Framework + Plugin 模式构建。将数据源读取和写入抽象为 Reader/Writer 插件，纳入到整个同步框架中。

* Reader 作为数据采集模块，负责采集数据源的数据，将数据发送给 Framework。

* Writer 作为数据写入模块，负责不断向 Framework 获取数据，并将数据写入到目的端。

* Framework 用于连接 Reader 和 Writer，作为两者的数据传输通道，并处理缓冲、流控、并发、数据转换等核心技术问题。

## DataX 使用示例

DataX 安装后，默认目录在 /home/admin/datax3 。该目录下有个子目录 job ，其中的 job.json 配置文件可以用来验证 DataX 是否安装成功。

每个任务的参数存放在一个 json 格式的文件中，主要由一个 reader 和一个 writer 组成。以下是任务配置示例文件 job.json：

```unknow
[admin /home/admin/datax3/job]
$cat job.json
{
    "job": {
        "setting": {
            "speed": {
                "byte":10485760
            },
            "errorLimit": {
                "record": 0,
                "percentage": 0.02
            }
        },
        "content": [
            {
                "reader": {
                    "name": "streamreader",
                    "parameter": {
                        "column" : [
                            {
                                "value": "DataX",
                                "type": "string"
                            },
                            {
                                "value": 19700604,
                                "type": "long"
                            },
                            {
                                "value": "1970-06-04 00:00:00",
                                "type": "date"
                            },
                            {
                                "value": true,
                                "type": "bool"
                            },
                            {
                                "value": "test",
                                "type": "bytes"
                            }
                        ],
                        "sliceRecordCount": 100000
                    }
                },
                "writer": {
                    "name": "streamwriter",
                    "parameter": {
                        "print": false,
                        "encoding": "UTF-8"
                    }
                }
            }
        ]
    }
}
```

这个任务的配置文件的 reader 和 writer 类型是一个 stream，会检测 DataX 是否正确安装。

>**注意**
>
>运行之前请确保安装 JDK 1.8 和 Python 2.7 版本的运行环境。

```unknow
[admin@**** /home/admin/datax3]
$bin/datax.py job/job.json
```

运行结果如下：

>**说明**
>
>这个默认的任务参数关闭了数据流输出，所以看不到输出结果。

![开发者指南-迁移数据-使用DataX迁移-通用数据同步框架 DataX-p1 ](https://help-static-aliyun-doc.aliyuncs.com/assets/img/zh-CN/1239620561/p413485.png)

# 使用 OBLOADER 导入数据

OBLOADER 是一款使用 Java 开发的客户端导入工具。该工具提供了非常灵活的命令行选项，可在多种复杂的场景下，将结构和数据导入到 OceanBase 中。

## 背景信息

OBLOADER 主要与 OBDUMPER 搭配使用。但是在外部业务中，OBLOADER 同时支持如 Navicat、Mydumper 和 SQLDeveloper 等工具导出的 SQL 或者 CSV 格式的文件导入。OBLOADER 充分利用 OceanBase 分布式系统的特性，重点优化导入性能和稳定性，以及丰富运行监控信息提升用户体验。

## 产品功能

OBLOADER 提供向 OceanBase 数据库导入结构和数据的能力，主要具备以下功能特性：

* 支持导入数据库对象定义的语句。

* 支持导入标准的 CSV 格式和 SQL 格式的数据文件。

* 支持导入定长字节格式，字符串分隔格式以及 DDL 和 DML 混合的文件格式。

* 支持导入时，配置数据预处理的控制规则以及文件与表之间的字段映射关系。

* 支持导入限速、防导爆、断点恢复和自动重试等特性。

* 支持指定自定义的日志目录、保存坏数据和冲突数据等特性。

* 支持将 OSS 云存储中的数据导入到 OceanBase 数据库。

## 支持的 OceanBase 数据库

已支持的 OceanBase 模式与版本，如下表所示：

| **OceanBase 模式** |                                        **支持的版本号**                                        |
|------------------|------------------------------------------------------------------------------------------|
| Oracle 模式        | 2.0.x、2.1.x、2.2.20、2.2.30、2.2.50、2.2.70、2.2.71、2.2.72、2.2.76、3.1.x、3.2.x                 |
| MySQL 模式         | 1.4.70、1.4.72、1.4.75、1.4.78、1.4.79、2.2.30、2.2.50、2.2.70、2.2.71、2.2.72、2.2.76、3.1.x、3.2.x |

## 注意事项

* 标准的 CSV 格式请参考 RFC 4180 规范，建议导入时严格遵从 RFC 4180 规范。

* 导入大量数据时，请在运行的脚本中修改虚拟机的内存参数。

* 命令行参数指定的对象名、数据文件名、规则文件名要求大小写一致。Oracle 默认大写，MySQL 默认小写。如果数据库中同时存在大写和小写的对象名，要求小写的对象名和文件名加上中括号。

* 导入的数据文件的命名规范是 table.group.sequence.suffix。

* 数据库对象存在依赖时，无法保证对象定义和数据按照依赖顺序导入。

* 无主键的表，暂不支持中断续传和数据替换。

* OceanBase MySQL 1.4.79 使用 `insert ... where not exists` 解决主键冲突时存在跨分区插入的错误。

* OceanBase MySQL 1.4.x 组合分区表 RANGE_COLUMNS + KEY 在虚拟路由视图中的元数据有缺陷。

* OBLOADER 可以支持的文件格式如下：

## 限制模式

>**说明**
>
>限制模式仅适用于用户无法直接提供 `--sys-user` 和 `--sys-password` 选项的场景。

* 使用限制模式（`--public-cloud`）导入数据到公共云部署的 OceanBase 集群时无需指定 `-t`, `-c` 连接选项。导入数据到私有云部署的 OceanBase 集群时需要指定 `-t` 连接选项，连接 ODP 服务时还需要加上 `-c` 选项。如果用户未使用限制模式，OBLOADER 必须指定 `--sys-user` 和 `--sys-password` 选项。

* 限制模式会影响导入的功能、性能以及稳定性。OceanBase 2.2.30 及之后版本已支持服务端限流的功能，所以使用限制模式时为保证数据导入的稳定性，可通过以下命令设置服务端限流阈值：

  ```sql
  alter system set freeze_trigger_percentage=50;
  alter system set minor_merge_concurrence=64;
  alter system set writing_throttling_trigger_percentage=80 tenant='xxx';
  ```

## 语法格式

将表结构和数据导入 OceanBase 数据库时，建议将它们分开导入。
OBLOADER 命令语法如下：

```sql
./obloader -h <主机IP> -P <端⼝> -u <⽤⼾> -p <密码>  --sys-user <sys 租户下的 root 用户或 proxyro 用户> --sys-password <sys 租⼾下的账⼾密码> -c <集群> -t <租⼾> -D <Schema 库名> [--ddl] [--csv|--sql] [--all|--table '表名'] -f<数据⽂件或者⽬录>
```

|       参数      | 是否必选 |   说明        |              示例              |
|-----------------|------|---------------------------|----------------------|
| -h(--host)      | 是    | 连接 OBProxy 或者 OBServer 的 IP。                                                        | -h 127.0.0.1                 |
| -P(--port)      | 是    | 连接 OBProxy 或者 OBServer 的端口。 <blockquote><b>说明</b></br><ul><li>直连访问数据库默认使用 2881 端口，可以自定义。</li><li> 通过 OBProxy 代理连接一般使用 2883 端口，可以自定义。</li></ul> </blockquote>   | -P 2881                      |
| -c(--cluster)   | 否    | 数据库的集群名。直连 OBServer 时无需指定。                                                          | -c 'cluste1'                 |
| -t(--tenant)    | 否    | 当前用户的租户名。      | -t sys                       |
| -u(--user)      | 是    | 数据库用户名。        | -u root                      |
| -p(--password)  | 否    | 数据库密码。         | -p '\*\*1\*\*\*'             |
| -D(--database)  | 否    | 数据库名。          | -D 'database1'               |
| -f(--file-path) | 是    | 指定数据文件所在的目录，或者是数据文件绝对路径。                                                            | -f '/path/file'              |
| --sys-user      | 否    | 指定 sys 租户下某用户，默认是 root@sys 用户。 <blockquote><b>注意</b></br> 导入的时候 OBLOADER 需要取表结构元数据信息，也需要链接到 sys 租户下。推荐您使用用户 `proxyro`。    </blockquote>                  | --sys-user 'root@sys'        |
| --sys-password  | 否    | 指定 sys 租户下某用户的密码，默认为空。                                                              | --sys-password '\*\*1\*\*\*' |
| --ddl           | 否    | 导入 DDL 文件。默认文件后缀是 -schema.sql。                                                      | --ddl                        |
| --sql           | 否    | 导入 SQL 文件。默认文件后缀是 .sql。                                                             | --sql                        |
| --mix           | 否    | 导入结构与数据混合的数据文件。| --mix                        |
| --csv           | 否    | 导入 CSV 文件（推荐）。默认文件后缀是 .csv。                                                         | --csv                        |
| --all           | 否    | 导入所有的数据库对象的结构定义。                                                                    | --all                        |
| --table         | 否    | 指定待导入的表，多个表用逗号分隔。值为 '\*' 时则导入 -D 库中所有的表。                                            | --table 'table1'             |

有关 OBLOADER 参数说明详情，请参见 [OBLOADER 命令行选项](https://www.oceanbase.com/docs/enterprise/obloader-obdumper/obloader-obdumper/V3.1.0/obloader-command-line-options)。

## 导入表结构

下文展示了将数据导出文件导入到租户 `obmysql` 的数据库 `test2` 下。

```sql
[root@obce-0000 ob-loader-dumper-3.0.0-SNAPSHOT]# bin/obloader -h 10.0.0.0 -P 2883 -u u_loader -p 123456 --sys-user=proxyro --sys-password=uY7Yf8zx -c obce-3zones -t obmysql -D test2 --ddl --all -f /tmp/obdumper
2021-09-29 21:26:05 [INFO] Parsed args:
-h[--host] 10.0.0.0
-P[--port] 2883
-u[--user] u_loader
-p[--password] ******
[--sys-user] proxyro
[--sys-password] ******
-c[--cluster] obce-3zones
-t[--tenant] obmysql
-D[--database] test2
[--ddl]
[--all]
-f[--file-path] /tmp/obdumper

2021-12-29 14:02:25 [INFO] The security certificate file: "/ob-loader-dumper-3.0.0-SNAPSHOT/conf/secure.crt" is not exists
2021-12-29 14:02:25 [INFO] No control files were defined in the path: "/tmp/obdumper"
2021-12-29 14:02:25 [INFO] Load jdbc driver class: "com.oceanbase.jdbc.Driver" finished
2021-12-29 14:02:25 [INFO] The manifest file: "/tmp/obdumper/data/MANIFEST.bin" has been saved
2021-12-29 14:02:26 [INFO] Init writer thread pool finished
2021-12-29 14:02:26 [WARN] The object type : "SEQUENCE" doesn't exist in the -schema.sql files
2021-12-29 14:02:26 [INFO] No.1 sql of the file: "/tmp/obdumper/data/test/TABLE/test1-schema.sql" exec  success . Elapsed: 141.6 ms
2021-12-29 14:02:26 [INFO] Load file: "test1-schema.sql" finished
2021-12-29 14:02:26 [INFO] No.1 sql of the file: "/tmp/obdumper/data/test/TABLE/test0-schema.sql" exec  success . Elapsed: 227.2 ms
2021-12-29 14:02:26 [INFO] Load file: "test0-schema.sql" finished
2021-12-29 14:02:26 [WARN] The object type : "VIEW" doesn't exist in the -schema.sql files
2021-12-29 14:02:26 [WARN] The object type : "FUNCTION" doesn't exist in the -schema.sql files
2021-12-29 14:02:26 [WARN] The object type : "PROCEDURE" doesn't exist in the -schema.sql files
2021-12-29 14:02:26 [WARN] The object type : "TRIGGER" doesn't exist in the -schema.sql files
2021-12-29 14:02:26 [WARN] The object type : "PACKAGE" doesn't exist in the -schema.sql files
2021-12-29 14:02:26 [WARN] The object type : "TYPE" doesn't exist in the -schema.sql files
2021-12-29 14:02:26 [WARN] The object type : "PACKAGE_BODY" doesn't exist in the -schema.sql files
2021-12-29 14:02:26 [WARN] The object type : "TYPE_BODY" doesn't exist in the -schema.sql files
2021-12-29 14:02:26 [WARN] The object type : "SYNONYM" doesn't exist in the -schema.sql files
2021-12-29 14:02:26 [WARN] The object type : "PUBLIC_SYNONYM" doesn't exist in the -schema.sql files
2021-12-29 14:02:27 [INFO] Close connection count: 1 of the DataSource. Key: 11_124_5_29_44564_857230679_test
2021-12-29 14:02:27 [INFO] Close connection count: 0 of the DataSource. Key: 11_124_5_29_44564_167438737_oceanbase
2021-12-29 14:02:27 [INFO] Shutdown task context finished
2021-12-29 14:02:27 [INFO] 
Finished Tasks: 2 Running Tasks: 0 Progress: 100.00%
2021-12-29 14:02:27 [INFO] 

All Load Tasks Finished: 

----------------------------------------------------------------------------------------------------------------------------
        No.#        |        Type        |             Name             |            Count             |       Status       
----------------------------------------------------------------------------------------------------------------------------
         1          |       TABLE        |            test0             |              1               |      SUCCESS       
         2          |       TABLE        |            test1             |              1               |      SUCCESS       
----------------------------------------------------------------------------------------------------------------------------

Total Count: 2  End Time: 2021-12-29 14:02:27


2021-12-29 14:02:27 [INFO] Load schema finished. Total Elapsed: 1.057 s
2021-12-29 14:02:27 [INFO] System exit 0

[root@obce-0000 ob-loader-dumper-3.0.0-SNAPSHOT]#
```

## 导入数据

```sql
[root@obce-0000 ob-loader-dumper-3.0.0-SNAPSHOT]# bin/obloader -h 10.0.0.0 -P 2883 -u u_loader -p 123456 --sys-user=proxyro --sys-password=uY7Yf8zx -c obce-3zones -t obmysql -D test2 --csv --all -f /tmp/obdumper
2021-09-29 21:27:53 [INFO] Parsed args:
-h[--host] 10.0.0.0
-P[--port] 2883
-u[--user] u_loader
-p[--password] ******
[--sys-user] proxyro
[--sys-password] ******
-c[--cluster] obce-3zones
-t[--tenant] obmysql
-D[--database] test2
[--csv]
[--all]
-f[--file-path] /tmp/obdumper

2021-12-29 14:07:21 [INFO] The security certificate file: "/ob-loader-dumper-3.0.0-SNAPSHOT/conf/secure.crt" is not exists
2021-12-29 14:07:21 [INFO] No control files were defined in the path: "/tmp/obdumper"
2021-12-29 14:07:21 [INFO] Load jdbc driver class: "com.oceanbase.jdbc.Driver" finished
2021-12-29 14:07:21 [INFO] The manifest file: "/tmp/obdumper/data/MANIFEST.bin" has been saved
2021-12-29 14:07:22 [INFO] Query the column metadata for the table: "test0" finished
2021-12-29 14:07:22 [INFO] Query the column metadata for the table: "test1" finished
2021-12-29 14:07:22 [INFO] Binding table: "test0" to the file: "/tmp/obdumper/data/test/TABLE/test0.0.0.csv" finished
2021-12-29 14:07:22 [WARN] File: "/tmp/obdumper/data/test/TABLE/test0-schema.sql" is unmatched on the suffix[.csv], ignore it
2021-12-29 14:07:22 [WARN] File: "/tmp/obdumper/data/test/TABLE/test1-schema.sql" is unmatched on the suffix[.csv], ignore it
2021-12-29 14:07:22 [WARN] File: "/tmp/obdumper/data/MANIFEST.bin" is unmatched on the suffix[.csv], ignore it
2021-12-29 14:07:22 [WARN] File: "/tmp/obdumper/data/CHECKPOINT.bin" is unmatched on the suffix[.csv], ignore it
2021-12-29 14:07:22 [INFO] Splitted 1 csv subfiles by 64.0 MB. Elapsed: 15.57 ms
2021-12-29 14:07:22 [INFO] Generate 1 subfiles finished
2021-12-29 14:07:22 [INFO] Ignore to clean any tables as --truncate-table or --delete-from-table is not specified
2021-12-29 14:07:22 [INFO] Ignore to query table entry for table: "test1" without datafiles. Remain: 1
2021-12-29 14:07:22 [INFO] Query table entry and primary key for table: "test0" finished. Remain: 0
2021-12-29 14:07:22 [INFO] Ignore to shuffle data files for table: "test1" without datafiles. Remain: 1
2021-12-29 14:07:50 [INFO] Query the leader location "test0" in multi unit finished. Elapsed: 73.12 ms
2021-12-29 14:07:50 [INFO] Query the leader location of "test0" finished. Remain: 0
2021-12-29 14:07:50 [INFO] Calculate leader: 10.10.10.1:11141 of table: "test0", part: 0. Remain: 0
2021-12-29 14:07:50 [INFO] Waiting to refresh observer load status ......
2021-12-29 14:07:50 [INFO] Refresh the observer load status success. Table: "test0". Remain: 0
2021-12-29 14:07:50 [INFO] Refresh observer load status finished. Elapsed: 116.4 ms
2021-12-29 14:07:50 [INFO] Create 16384 slots for ring buffer finished. [10.10.10.1:11141]
2021-12-29 14:07:51 [INFO] Start 192 database writer threads finished. [10.10.10.1:11141]
2021-12-29 14:07:51 [INFO] Start 38 csv file reader threads successed
2021-12-29 14:07:51 [INFO] File: "/tmp/obdumper/data/test/TABLE/test0.0.0.csv" has been parsed finished
2021-12-29 14:07:55 [INFO] 

1. Enqueue Performance Monitor: 
-------------------------------------------------------------------------------------------------------
 Dimension \ Metric |             Tps              |          Throughput          |       Buffer       
-------------------------------------------------------------------------------------------------------
     1.sec.avg      |       2.03 Records/sec       |          0.0 KB/sec          |      1 Slots       
     1.min.avg      |       0.0 Records/min        |          0.0 KB/min          |      1 Slots       
       Total        |          10 Records          |            0.0 KB            |      1 Slots       
-------------------------------------------------------------------------------------------------------

2. Dequeue Performance Monitor: 
-------------------------------------------------------------------------------------------------------
 Dimension \ Metric |             Tps              |          Throughput          |       Buffer       
-------------------------------------------------------------------------------------------------------
     1.sec.avg      |       2.0 Records/sec        |          0.0 KB/sec          |      1 Slots       
     1.min.avg      |       2.0 Records/min        |          2.0 KB/min          |      1 Slots       
       Total        |          10 Records          |            0.0 KB            |      1 Slots       
-------------------------------------------------------------------------------------------------------

2021-12-29 14:08:13 [INFO] Wait for the all the workers to drain of published events then halt the workers
2021-12-29 14:08:13 [INFO] Close connection count: 4 of the DataSource. Key: 11_124_5_29_44564_857230679_test
2021-12-29 14:08:14 [INFO] Close connection count: 17 of the DataSource. Key: 11_124_5_29_44564_167438737_oceanbase
2021-12-29 14:08:14 [INFO] Shutdown task context finished
2021-12-29 14:08:14 [INFO] 
Finished Tasks: 1 Running Tasks: 0 Progress: 100.00%
2021-12-29 14:08:14 [INFO] 

All Load Tasks Finished: 

----------------------------------------------------------------------------------------------------------------------------
        No.#        |        Type        |             Name             |            Count             |       Status       
----------------------------------------------------------------------------------------------------------------------------
         1          |       TABLE        |            test0             |           10 -> 10           |      SUCCESS       
----------------------------------------------------------------------------------------------------------------------------

Total Count: 10  End Time: 2021-12-29 14:08:14


2021-12-29 14:08:14 [INFO] Load record finished. Total Elapsed: 2.05 s
2021-12-29 14:08:14 [INFO] System exit 0
```

## 检查导入的表结构和数据

```sql
MySQL [test]> SHOW create table test2.t1\G
*************************** 1. row ***************************
       Table: t1
Create Table: CREATE TABLE `t1` (
  `id` bigint(20) NOT NULL AUTO_INCREMENT,
  `c1` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP,
  PRIMARY KEY (`id`)
) AUTO_INCREMENT = 1 DEFAULT CHARSET = utf8mb4 ROW_FORMAT = COMPACT COMPRESSION = 'zstd_1.3.8' REPLICA_NUM = 3 BLOCK_SIZE = 16384 USE_BLOOM_FILTER = FALSE TABLET_SIZE = 134217728 PCTFREE = 0
1 row in set (0.012 sec)

MySQL [test]> SELECT * FROM test2.t1;
+----+---------------------+
| id | c1                  |
+----+---------------------+
|  1 | 2021-09-29 21:16:03 |
|  2 | 2021-09-29 21:16:05 |
|  3 | 2021-09-29 21:16:05 |
|  4 | 2021-09-29 21:16:06 |
|  5 | 2021-09-29 21:16:06 |
|  6 | 2021-09-29 21:16:18 |
|  7 | 2021-09-29 21:16:18 |
|  8 | 2021-09-29 21:16:19 |
+----+---------------------+
8 rows in set (0.015 sec)
```

## 更多信息

关于 OBLOADER 的更多使用信息，请参见 [数据处理](https://www.oceanbase.com/docs/enterprise/obloader-obdumper/obloader-obdumper/V3.1.0/obloader-define-control-files)。
